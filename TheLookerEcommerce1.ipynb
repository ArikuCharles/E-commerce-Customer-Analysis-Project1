{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad946cf0-6f28-4e68-9415-dd0cfdfa395b",
   "metadata": {},
   "source": [
    "# E-commerce Customer Analysis Project\n",
    "\n",
    "# The Look Ecommerce Data Analysis\n",
    "\n",
    "# Analyst: Ariku Charles\n",
    "\n",
    "# Client: The Look Online Clothing Store\n",
    "\n",
    "# Date: 11 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19bacb7-4ea6-4d8d-b820-cb066cb15c66",
   "metadata": {},
   "source": [
    "\n",
    "# E-commerce Customer Analysis Project\n",
    "\n",
    "# Objective\n",
    "\n",
    "To analyze The Look's e-commerce data to identify high-value customer segments, optimize marketing channel allocation, improve product profitability, and streamline operational efficiency, ultimately increasing customer lifetime value and overall business profitability.\n",
    "\n",
    "# Problem Statement\n",
    "\n",
    "The Look faces multiple interconnected challenges affecting profitability and growth:\n",
    "\n",
    "Ineffective marketing spend with unclear ROI by channel\n",
    "\n",
    "Suboptimal product performance and high return rates\n",
    "\n",
    "Operational inefficiencies in fulfillment processes\n",
    "\n",
    "Inability to identify and retain high-value customers\n",
    "\n",
    "Disconnected insights across business functions\n",
    "\n",
    "# Key Questions to Answer\n",
    "\n",
    "Which marketing channels deliver customers with the highest lifetime value?\n",
    "\n",
    "What product characteristics correlate with high profitability and low returns?\n",
    "\n",
    "Where are the bottlenecks in the order fulfillment process?\n",
    "\n",
    "Which customer segments demonstrate the highest completion rates and loyalty?\n",
    "\n",
    "How can operational processes be optimized to reduce cancellations and returns?\n",
    "\n",
    "# Success Metrics\n",
    "\n",
    "Order completion rates.\n",
    "\n",
    "Return rates.\n",
    "\n",
    "Improve customer lifetime value\n",
    "\n",
    "Optimize marketing channel ROI\n",
    "\n",
    "Enhance operational efficiency\n",
    "\n",
    "# Deliverables\n",
    "\n",
    "Customer segmentation analysis with RFM scoring\n",
    "\n",
    "Marketing channel performance assessment\n",
    "\n",
    "Product profitability and return analysis\n",
    "\n",
    "Operational bottleneck identification\n",
    "\n",
    "Actionable strategic recommendations\n",
    "\n",
    "# Stakeholders\n",
    "Executive leadership, marketing team, operations managers, product merchandising, customer experience, and finance department.\n",
    "\n",
    "# Dataset\n",
    "The dataset used is The Look E-commerce Dataset, a synthetic dataset from Looker simulating a fictional clothing retailer (7 interconnected CSV files: users, orders, order items, products, events, inventory items, and distribution centers). It's available as a public dataset on Google BigQuery and can be downloaded as CSV files from the BigQuery console or Kaggle. For this analysis, the CSV files were stored locally at E:\\TheLookEcommerce.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ccd97c-8b9c-4c12-a863-d41a73cdeb32",
   "metadata": {},
   "source": [
    "# Data Sources\n",
    "\n",
    "## Primary Dataset\n",
    "**Name**: The Look E-commerce Dataset  \n",
    "**Source**: Looker/Google BigQuery Public Datasets  \n",
    "**Format**: 7 interconnected CSV files  \n",
    "**Purpose**: Synthetic e-commerce data for analytics training\n",
    "\n",
    "## Dataset Structure\n",
    "| File | Rows | Description |\n",
    "|------|------|-------------|\n",
    "| `users.csv` | 100,000 | Customer profiles and demographics |\n",
    "| `orders.csv` | 125,226 | Customer purchase records |\n",
    "| `products.csv` | 29,120 | Product catalog and pricing |\n",
    "| `order_items.csv` | 181,759 | Individual order line items |\n",
    "| `events.csv` | 1,048,575 | Website user interactions |\n",
    "| `inventory_items.csv` | 490,705 | Stock management |\n",
    "| `distribution_centers.csv` | 10 | Warehouse locations |\n",
    "\n",
    "## Data Quality (ROCCC)\n",
    "- **Reliable**: Structured synthetic data from Google\n",
    "- **Comprehensive**: Complete e-commerce ecosystem\n",
    "- **Current**: Multi-year data with recent timestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79700594-49e5-4099-96d1-a2c620405b94",
   "metadata": {},
   "source": [
    "# Data Cleaning & Manipulation\n",
    "## Importing packages/Libraries\n",
    "These Packages/libraries provide the necessary tools for comprehensive file handling and data analysis. Pandas enables efficient data manipulation, while scipy allows for statistical hypothesis testing. Visualization libraries help in exploratory data analysis and result presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b62e7263-30a4-49d3-b599-7986be9945ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTILITIES\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# DATA MANIPULATION & ANALYSIS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# VISUALIZATION\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "# MACHINE LEARNING\n",
    "import sklearn\n",
    "# STATISTICS\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabfc9e6-ebaf-4fb9-9a5e-108adae166d1",
   "metadata": {},
   "source": [
    "# Data Loading with OOP Structure\n",
    "\n",
    "Created a custom Python class TheLookEcommerce that loads all 7 CSV files as class attributes using pandas' read_csv() function.\n",
    "Using Object-Oriented Programming (OOP) provides organized data management, keeps related datasets together, and allows for method encapsulation. This structure makes the data easily accessible and maintainable throughout the analysis.\n",
    "The Main class With initialising function for the Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d0268ba-77ae-4949-b857-d1a5679d46ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine the entire class with the new method\n",
    "class TheLookEcommerce:\n",
    "    \n",
    "    def __init__(self, data_path):\n",
    "        # Load all 7 files directly in constructor\n",
    "        self.distribution_centers = pd.read_csv(f\"{data_path}/distribution_centers.csv\")\n",
    "        self.events = pd.read_csv(f\"{data_path}/events.csv\")\n",
    "        self.inventory_items = pd.read_csv(f\"{data_path}/inventory_items.csv\")\n",
    "        self.order_items = pd.read_csv(f\"{data_path}/order_items.csv\")\n",
    "        self.orders = pd.read_csv(f\"{data_path}/orders.csv\")\n",
    "        self.products = pd.read_csv(f\"{data_path}/products.csv\")\n",
    "        self.users = pd.read_csv(f\"{data_path}/users.csv\")\n",
    "    \n",
    "    def check_files_loaded(self):\n",
    "        \"\"\"Check if all 7 files have loaded successfully\"\"\"\n",
    "        \n",
    "        print(\"Checking loaded files...\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        files = [\n",
    "            (\"distribution_centers\", self.distribution_centers),\n",
    "            (\"events\", self.events),\n",
    "            (\"inventory_items\", self.inventory_items),\n",
    "            (\"order_items\", self.order_items),\n",
    "            (\"orders\", self.orders),\n",
    "            (\"products\", self.products),\n",
    "            (\"users\", self.users)\n",
    "        ]\n",
    "        \n",
    "        for name, data in files:\n",
    "            if data is not None:\n",
    "                print(f\"‚úÖ {name}: {data.shape[0]} rows, {data.shape[1]} columns\")\n",
    "            else:\n",
    "                print(f\"‚ùå {name}: NOT LOADED\")\n",
    "        \n",
    "        print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b9b8ecf-b290-4b36-b35e-425036629115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking loaded files...\n",
      "----------------------------------------\n",
      "‚úÖ distribution_centers: 10 rows, 4 columns\n",
      "‚úÖ events: 1048575 rows, 13 columns\n",
      "‚úÖ inventory_items: 490705 rows, 12 columns\n",
      "‚úÖ order_items: 181759 rows, 11 columns\n",
      "‚úÖ orders: 125226 rows, 9 columns\n",
      "‚úÖ products: 29120 rows, 9 columns\n",
      "‚úÖ users: 100000 rows, 15 columns\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "thelook = TheLookEcommerce(\"E:/TheLookEcommerce\")\n",
    "thelook.check_files_loaded()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e43baf5-1ea3-49be-a598-2b6f78806d8f",
   "metadata": {},
   "source": [
    "### Initial Data Verification\n",
    "Verified that all 7 files loaded successfully with their expected row and column counts, confirming data integrity from source to analysis environment.\n",
    "Initial verification ensures that no data was corrupted during transfer or loading. Confirming expected dimensions provides confidence that the complete dataset is available for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ab9944-6437-4404-ad74-ea31546adbd1",
   "metadata": {},
   "source": [
    "# Data Structure Examination\n",
    "Examined the structure of key tables including column names, data types, and basic statistics for numerical columns.\n",
    "Understanding data structure is essential for selecting appropriate analysis methods. Different data types require different handling - numerical data allows statistical tests, while categorical data requires different analytical approaches.\n",
    "We need to understand the structure of our data before cleaning it. \n",
    "### Starting with User Data Analysis\n",
    "we will begin with the users.csv.Users are the core of e-commerce analysis. All business questions about sales, marketing, and growth ultimately connect back to customers. By examining users data first, we build a clean customer foundation that supports accurate analysis of purchases, browsing behavior, and preferences. This initial inspection checks data structure, types, missing values, and quality issues to ensure our customer insights are reliable before connecting to orders, events, and products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f5368da-97e0-4a18-9f4e-eba5c79f8756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Users Data Inspection\n",
      "----------------------------------------\n",
      "Rows: 100,000\n",
      "Columns: 15\n",
      "\n",
      "üìã Data Types:\n",
      "  id                   - int64\n",
      "  first_name           - object\n",
      "  last_name            - object\n",
      "  email                - object\n",
      "  age                  - int64\n",
      "  gender               - object\n",
      "  state                - object\n",
      "  street_address       - object\n",
      "  postal_code          - object\n",
      "  city                 - object\n",
      "  country              - object\n",
      "  latitude             - float64\n",
      "  longitude            - float64\n",
      "  traffic_source       - object\n",
      "  created_at           - object\n",
      "\n",
      "‚ö†Ô∏è  Missing Values:\n",
      "  city                 - 958 (1.0%)\n",
      "\n",
      "üîç Duplicate Check:\n",
      "  Duplicate customer IDs: 0\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "     def inspect_users():\n",
    "        \"\"\"Check users data: structure, types, missing values, duplicates\"\"\"\n",
    "        \n",
    "        print(\"üîç Users Data Inspection\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        data = thelook.users\n",
    "        \n",
    "        # 1. Structure\n",
    "        print(f\"Rows: {data.shape[0]:,}\")\n",
    "        print(f\"Columns: {data.shape[1]}\")\n",
    "        \n",
    "        # 2. Data types\n",
    "        print(\"\\nüìã Data Types:\")\n",
    "        for col, dtype in data.dtypes.items():\n",
    "            print(f\"  {col:20} - {dtype}\")\n",
    "        \n",
    "        # 3. Missing values\n",
    "        print(\"\\n‚ö†Ô∏è  Missing Values:\")\n",
    "        missing = data.isnull().sum()\n",
    "        \n",
    "        if missing.sum() == 0:\n",
    "            print(\"  No missing values\")\n",
    "        else:\n",
    "            for col in data.columns:\n",
    "                if data[col].isnull().sum() > 0:\n",
    "                    count = data[col].isnull().sum()\n",
    "                    percent = (count / len(data)) * 100\n",
    "                    print(f\"  {col:20} - {count:,} ({percent:.1f}%)\")\n",
    "        \n",
    "        # 4. Duplicate check\n",
    "        print(\"\\nüîç Duplicate Check:\")\n",
    "        duplicate_ids = data['id'].duplicated().sum()\n",
    "        print(f\"  Duplicate customer IDs: {duplicate_ids}\")\n",
    "        \n",
    "        print(\"-\" * 40)\n",
    "        return data\n",
    "    \n",
    "    # Run inspection\n",
    "users_data = inspect_users()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8306e229-7bb7-4b10-8a84-042a119e60e6",
   "metadata": {},
   "source": [
    "# Traffic Source Analysis\n",
    "Filtered and summarized users by their acquisition source using the traffic_source column. Aggregated customer counts and calculated percentage distribution across all five marketing channels.\n",
    "Understanding customer acquisition patterns helps optimize marketing spend. By quantifying where customers come from, we can identify which channels drive the most volume and which may require strategic evaluation for improvement or reallocation of resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "82b47a7b-3b72-4855-b662-cf6cfa16cff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà Traffic Source Analysis\n",
      "----------------------------------------\n",
      "Total customers: 100,000\n",
      "Unique traffic sources: 5\n",
      "\n",
      "üìä Customer Count by Source:\n",
      "  Search          - 70,075 customers ( 70.1%)\n",
      "  Organic         - 15,110 customers ( 15.1%)\n",
      "  Facebook        -  5,816 customers (  5.8%)\n",
      "  Email           -  4,947 customers (  4.9%)\n",
      "  Display         -  4,052 customers (  4.1%)\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "    def analyze_traffic_source():\n",
    "        \"\"\"Analyze where customers come from (traffic sources)\"\"\"\n",
    "        \n",
    "        print(\"üìà Traffic Source Analysis\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        data = thelook.users\n",
    "        \n",
    "        if 'traffic_source' not in data.columns:\n",
    "            print(\"‚ùå No traffic_source column found\")\n",
    "            return\n",
    "        \n",
    "        # 1. Basic counts\n",
    "        traffic_counts = data['traffic_source'].value_counts()\n",
    "        \n",
    "        print(f\"Total customers: {len(data):,}\")\n",
    "        print(f\"Unique traffic sources: {data['traffic_source'].nunique()}\")\n",
    "        \n",
    "        print(\"\\nüìä Customer Count by Source:\")\n",
    "        for source, count in traffic_counts.items():\n",
    "            percent = (count / len(data)) * 100\n",
    "            print(f\"  {source:15} - {count:6,} customers ({percent:5.1f}%)\")\n",
    "        \n",
    "        print(\"-\" * 40)\n",
    "        return traffic_counts\n",
    "\n",
    "# Run analysis\n",
    "traffic_summary = analyze_traffic_source()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862d9775-89fa-434a-bbae-27c86758731c",
   "metadata": {},
   "source": [
    "The analysis shows the distribution of customers across five traffic sources, revealing that Search marketing dominates with 70.1% of customers, followed by Organic traffic at 15.1%. Facebook, Email, and Display channels collectively account for only 14.8% of the customer base.\n",
    "\n",
    "This customer count distribution reveals little about customer quality, purchase behavior, or business value. High customer volume from Search doesn't indicate whether these customers complete purchases, have high lifetime value, or represent profitable acquisitions. We only know where customers come from, not what they do afterwords.\n",
    "\n",
    "To address this limitation, we must aggregate traffic sources by order status to analyze how customers from different channels actually behave. This involves connecting user traffic source data with their order outcomes to determine completion rates, return rates, and cancellation patterns by acquisition channel. This deeper analysis will reveal whether high-volume channels also deliver high-quality customers and successful purchase outcomes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9fce59a5-baaa-4e78-81ff-ec23cb3e76ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis of order status by traffic source...\n",
      "üîÑ Order Status Analysis by Traffic Source\n",
      "======================================================================\n",
      "Step 1: Connecting users to their orders...\n",
      "Step 2: Connecting to order items...\n",
      "Step 3: Analyzing by traffic source...\n",
      "\n",
      "üìä ORDER STATUS BY TRAFFIC SOURCE\n",
      "----------------------------------------------------------------------\n",
      "Traffic Source  Total Items  Completed  Returned  Cancelled  Shipped  Processing Completion Rate\n",
      "      Facebook        10508       2690      1094       1514     3223        1987           25.6%\n",
      "       Display         7353       1861       727        998     2254        1513           25.3%\n",
      "        Search       127277      32044     12753      19140    37982       25358           25.2%\n",
      "       Organic        27535       6803      2757       4158     8228        5589           24.7%\n",
      "         Email         9086       2211       901       1280     2753        1941           24.3%\n",
      "\n",
      "======================================================================\n",
      "üéØ KEY FINDINGS\n",
      "======================================================================\n",
      "üèÜ BEST: Facebook - 25.6% completion rate\n",
      "   2,690 completed out of 10,508 items\n",
      "\n",
      "‚ö†Ô∏è  WORST: Email - 24.3% completion rate\n",
      "   2,211 completed out of 9,086 items\n",
      "\n",
      "üìà AVERAGE RETURN RATE BY SOURCE:\n",
      "   Facebook   -  10.4% returned\n",
      "   Display    -   9.9% returned\n",
      "   Search     -  10.0% returned\n",
      "   Organic    -  10.0% returned\n",
      "   Email      -   9.9% returned\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "    def analyze_order_status_by_traffic():\n",
    "        \"\"\"Analyze order item status by traffic source\"\"\"\n",
    "        \n",
    "        print(\"üîÑ Order Status Analysis by Traffic Source\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # Check we have all needed data\n",
    "        if thelook.users is None or thelook.orders is None or thelook.order_items is None:\n",
    "            print(\"‚ùå Missing required data (users, orders, or order_items)\")\n",
    "            return\n",
    "        \n",
    "        users = thelook.users\n",
    "        orders = thelook.orders\n",
    "        order_items = thelook.order_items\n",
    "        \n",
    "        # Step 1: Connect users to their orders\n",
    "        print(\"Step 1: Connecting users to their orders...\")\n",
    "        \n",
    "        # Merge orders with users to get traffic source\n",
    "        orders_with_source = pd.merge(\n",
    "            orders[['order_id', 'user_id']],\n",
    "            users[['id', 'traffic_source']],\n",
    "            left_on='user_id',\n",
    "            right_on='id',\n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        # Step 2: Connect to order items to get status\n",
    "        print(\"Step 2: Connecting to order items...\")\n",
    "        \n",
    "        # Merge with order items\n",
    "        items_with_source = pd.merge(\n",
    "            order_items[['order_id', 'status']],\n",
    "            orders_with_source[['order_id', 'traffic_source']],\n",
    "            on='order_id',\n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        # Step 3: Analyze by traffic source\n",
    "        print(\"Step 3: Analyzing by traffic source...\\n\")\n",
    "        \n",
    "        # Get unique traffic sources\n",
    "        traffic_sources = items_with_source['traffic_source'].dropna().unique()\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for source in traffic_sources:\n",
    "            # Filter items for this traffic source\n",
    "            source_items = items_with_source[items_with_source['traffic_source'] == source]\n",
    "            total_items = len(source_items)\n",
    "            \n",
    "            if total_items == 0:\n",
    "                continue\n",
    "            \n",
    "            # Count each status\n",
    "            status_counts = source_items['status'].value_counts()\n",
    "            \n",
    "            # Get common statuses\n",
    "            completed = status_counts.get('Complete', 0)\n",
    "            returned = status_counts.get('Returned', 0) \n",
    "            \n",
    "            # Calculate completion rate\n",
    "            completion_rate = (completed / total_items) * 100 if total_items > 0 else 0\n",
    "            \n",
    "            results.append({\n",
    "                'Traffic Source': source,\n",
    "                'Total Items': total_items,\n",
    "                'Completed': completed,\n",
    "                'Returned': returned,\n",
    "                'Cancelled': status_counts.get('Cancelled', 0),\n",
    "                'Shipped': status_counts.get('Shipped', 0),\n",
    "                'Processing': status_counts.get('Processing', 0),\n",
    "                'Completion Rate': f\"{completion_rate:.1f}%\"\n",
    "            })\n",
    "        \n",
    "        # Create results DataFrame\n",
    "        results_df = pd.DataFrame(results)\n",
    "        \n",
    "        # Sort by completion rate (highest first)\n",
    "        results_df['Sort_Rate'] = results_df['Completion Rate'].str.replace('%', '').astype(float)\n",
    "        results_df = results_df.sort_values('Sort_Rate', ascending=False)\n",
    "        results_df = results_df.drop('Sort_Rate', axis=1)\n",
    "        \n",
    "        # Display results\n",
    "        print(\"üìä ORDER STATUS BY TRAFFIC SOURCE\")\n",
    "        print(\"-\"*70)\n",
    "        \n",
    "        # Format the display\n",
    "        pd.set_option('display.width', 1000)\n",
    "        pd.set_option('display.max_columns', None)\n",
    "        \n",
    "        print(results_df.to_string(index=False))\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"üéØ KEY FINDINGS\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # Find best and worst performers\n",
    "        if not results_df.empty:\n",
    "            best_source = results_df.iloc[0]\n",
    "            worst_source = results_df.iloc[-1]\n",
    "            \n",
    "            print(f\"üèÜ BEST: {best_source['Traffic Source']} - {best_source['Completion Rate']} completion rate\")\n",
    "            print(f\"   {best_source['Completed']:,} completed out of {best_source['Total Items']:,} items\")\n",
    "            \n",
    "            print(f\"\\n‚ö†Ô∏è  WORST: {worst_source['Traffic Source']} - {worst_source['Completion Rate']} completion rate\")\n",
    "            print(f\"   {worst_source['Completed']:,} completed out of {worst_source['Total Items']:,} items\")\n",
    "            \n",
    "            # Calculate average return rate\n",
    "            print(f\"\\nüìà AVERAGE RETURN RATE BY SOURCE:\")\n",
    "            for _, row in results_df.iterrows():\n",
    "                return_rate = (row['Returned'] / row['Total Items']) * 100\n",
    "                print(f\"   {row['Traffic Source']:10} - {return_rate:5.1f}% returned\")\n",
    "        \n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        return results_df\n",
    "    \n",
    "    # Run the analysis\n",
    "    print(\"Starting analysis of order status by traffic source...\")\n",
    "    status_by_traffic = analyze_order_status_by_traffic()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3213a05-6b82-45b2-9302-f3b92e8cacaa",
   "metadata": {},
   "source": [
    "I analyzed purchase completion and return rates across different marketing channels to determine which acquisition sources deliver the most successful customers.\n",
    "By merging customer data (traffic source) with order records and item statuses, then filtering and calculating completion rates for each channel separately.\n",
    "To move beyond simple customer counts and understand which channels actually convert visitors into successful purchasers, informing marketing budget allocation.                                                                                                                              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42950cc1-9337-419a-bfb2-e115f33cffdf",
   "metadata": {},
   "source": [
    "# Statistical Testing with Chi-Square\n",
    "Percentages alone don't tell if differences matter. With different sample sizes (Search: 127,277 items vs. Email: 9,086 items), percentage comparisons can be misleading. Statistical testing determines if observed differences are meaningful or due to chance.\n",
    "Conducted chi-square tests of independence to evaluate whether completion and return rates significantly differ across traffic sources.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2c0a10-005a-42a4-b9ad-6e748fba859a",
   "metadata": {},
   "source": [
    "1. Research Question:\n",
    "Does the traffic source (Search, Organic, Facebook, Email, Display) affect the likelihood of order completion?\n",
    "2. Hypotheses:\n",
    "Null Hypothesis (H‚ÇÄ):\n",
    "Completion rates are equal across all traffic sources.\n",
    "Alternative Hypothesis (H‚ÇÅ):\n",
    "At least one traffic source has a different completion rate.\n",
    "3. Test:\n",
    "Chi-square test of independence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "57c3bdbe-641c-46f8-919b-9157990aa767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conducting proper statistical hypothesis test...\n",
      "======================================================================\n",
      "STATISTICAL HYPOTHESIS TESTING\n",
      "======================================================================\n",
      "\n",
      "üîç RESEARCH QUESTION:\n",
      "Does traffic source affect order completion rate?\n",
      "\n",
      "üìã HYPOTHESES:\n",
      "Null Hypothesis (H‚ÇÄ): Completion rates are EQUAL across all traffic sources\n",
      "Alternative Hypothesis (H‚ÇÅ): At least one traffic source has DIFFERENT completion rate\n",
      "\n",
      "üìä TEST DATA:\n",
      "----------------------------------------\n",
      "Source      Completed  Not Completed      Total\n",
      "----------------------------------------\n",
      "Facebook        2,690          7,818     10,508\n",
      "Display         1,861          5,492      7,353\n",
      "Search         32,044         95,233    127,277\n",
      "Organic         6,803         20,732     27,535\n",
      "Email           2,211          6,875      9,086\n",
      "\n",
      "üî¨ TEST EXECUTION: Chi-square test of independence\n",
      "----------------------------------------\n",
      "Chi-square statistic (œá¬≤): 7.0600\n",
      "Degrees of freedom (df): 4\n",
      "p-value: 0.1327530775\n",
      "\n",
      "‚öñÔ∏è DECISION RULE:\n",
      "Significance level (Œ±): 0.05\n",
      "If p-value < 0.05, reject H‚ÇÄ\n",
      "If p-value ‚â• 0.05, fail to reject H‚ÇÄ\n",
      "\n",
      "üìà STATISTICAL CONCLUSION:\n",
      "----------------------------------------\n",
      "‚ùå FAIL TO REJECT NULL HYPOTHESIS (p = 0.132753 ‚â• Œ± = 0.05)\n",
      "   There is insufficient evidence\n",
      "   that completion rates differ by traffic source\n",
      "\n",
      "üìè PRACTICAL SIGNIFICANCE (Effect Size):\n",
      "Cramer's V = 0.006232\n",
      "\n",
      "üìã EFFECT SIZE INTERPRETATION:\n",
      "Negligible effect - Differences are trivial\n",
      "\n",
      "üíº BUSINESS IMPLICATION:\n",
      "----------------------------------------\n",
      "No need to differentiate marketing strategy by traffic source\n",
      "All channels perform similarly in terms of completion\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "    def proper_chi_square_test():\n",
    "        \"\"\"Proper hypothesis test with research question and hypotheses\"\"\"\n",
    "        \n",
    "        print(\"=\"*70)\n",
    "        print(\"STATISTICAL HYPOTHESIS TESTING\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # ========== RESEARCH QUESTION ==========\n",
    "        print(\"\\nüîç RESEARCH QUESTION:\")\n",
    "        print(\"Does traffic source affect order completion rate?\")\n",
    "        \n",
    "        # ========== HYPOTHESES ==========\n",
    "        print(\"\\nüìã HYPOTHESES:\")\n",
    "        print(\"Null Hypothesis (H‚ÇÄ): Completion rates are EQUAL across all traffic sources\")\n",
    "        print(\"Alternative Hypothesis (H‚ÇÅ): At least one traffic source has DIFFERENT completion rate\")\n",
    "        \n",
    "        # ========== DATA ==========\n",
    "        print(\"\\nüìä TEST DATA:\")\n",
    "        print(\"-\"*40)\n",
    "        \n",
    "        # Raw counts from analysis\n",
    "        sources = ['Facebook', 'Display', 'Search', 'Organic', 'Email']\n",
    "        completed = [2690, 1861, 32044, 6803, 2211]\n",
    "        total = [10508, 7353, 127277, 27535, 9086]\n",
    "        not_completed = [t - c for t, c in zip(total, completed)]\n",
    "        \n",
    "        # Display data\n",
    "        print(f\"{'Source':10} {'Completed':>10} {'Not Completed':>14} {'Total':>10}\")\n",
    "        print(\"-\"*40)\n",
    "        for i in range(len(sources)):\n",
    "            print(f\"{sources[i]:10} {completed[i]:10,} {not_completed[i]:14,} {total[i]:10,}\")\n",
    "        \n",
    "        # ========== TEST EXECUTION ==========\n",
    "        print(\"\\nüî¨ TEST EXECUTION: Chi-square test of independence\")\n",
    "        print(\"-\"*40)\n",
    "        \n",
    "        # Create contingency table\n",
    "        contingency = np.array([completed, not_completed]).T\n",
    "        \n",
    "        # Run test\n",
    "        chi2, p_value, dof, expected = stats.chi2_contingency(contingency)\n",
    "        \n",
    "        print(f\"Chi-square statistic (œá¬≤): {chi2:.4f}\")\n",
    "        print(f\"Degrees of freedom (df): {dof}\")\n",
    "        print(f\"p-value: {p_value:.10f}\")\n",
    "        \n",
    "        # ========== DECISION RULE ==========\n",
    "        print(\"\\n‚öñÔ∏è DECISION RULE:\")\n",
    "        alpha = 0.05  # Significance level\n",
    "        print(f\"Significance level (Œ±): {alpha}\")\n",
    "        print(f\"If p-value < {alpha}, reject H‚ÇÄ\")\n",
    "        print(f\"If p-value ‚â• {alpha}, fail to reject H‚ÇÄ\")\n",
    "        \n",
    "        # ========== STATISTICAL CONCLUSION ==========\n",
    "        print(\"\\nüìà STATISTICAL CONCLUSION:\")\n",
    "        print(\"-\"*40)\n",
    "        \n",
    "        if p_value < alpha:\n",
    "            print(f\"‚úÖ REJECT NULL HYPOTHESIS (p = {p_value:.6f} < Œ± = {alpha})\")\n",
    "            print(\"   There is statistically significant evidence\")\n",
    "            print(\"   that completion rates differ by traffic source\")\n",
    "        else:\n",
    "            print(f\"‚ùå FAIL TO REJECT NULL HYPOTHESIS (p = {p_value:.6f} ‚â• Œ± = {alpha})\")\n",
    "            print(\"   There is insufficient evidence\")\n",
    "            print(\"   that completion rates differ by traffic source\")\n",
    "        \n",
    "        # ========== PRACTICAL SIGNIFICANCE ==========\n",
    "        print(\"\\nüìè PRACTICAL SIGNIFICANCE (Effect Size):\")\n",
    "        n = sum(total)\n",
    "        cramers_v = np.sqrt(chi2 / (n * (min(contingency.shape) - 1)))\n",
    "        print(f\"Cramer's V = {cramers_v:.6f}\")\n",
    "        \n",
    "        print(\"\\nüìã EFFECT SIZE INTERPRETATION:\")\n",
    "        if cramers_v < 0.1:\n",
    "            print(\"Negligible effect - Differences are trivial\")\n",
    "        elif cramers_v < 0.2:\n",
    "            print(\"Small effect - Minor practical importance\")\n",
    "        elif cramers_v < 0.3:\n",
    "            print(\"Medium effect - Moderate practical importance\")\n",
    "        else:\n",
    "            print(\"Large effect - Substantial practical importance\")\n",
    "        \n",
    "        # ========== BUSINESS IMPLICATION ==========\n",
    "        print(\"\\nüíº BUSINESS IMPLICATION:\")\n",
    "        print(\"-\"*40)\n",
    "        \n",
    "        if p_value >= alpha:\n",
    "            print(\"No need to differentiate marketing strategy by traffic source\")\n",
    "            print(\"All channels perform similarly in terms of completion\")\n",
    "        elif cramers_v < 0.1:\n",
    "            print(\"Statistically significant but practically negligible\")\n",
    "            print(\"Focus on overall funnel improvement, not channel optimization\")\n",
    "        else:\n",
    "            print(\"Both statistically and practically significant\")\n",
    "            print(\"Consider channel-specific optimization strategies\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        \n",
    "        return {\n",
    "            'chi2': chi2,\n",
    "            'p_value': p_value,\n",
    "            'cramers_v': cramers_v,\n",
    "            'decision': 'reject' if p_value < alpha else 'fail to reject'\n",
    "        }\n",
    "    \n",
    "    # Run the proper test\n",
    "    print(\"Conducting proper statistical hypothesis test...\")\n",
    "    test_results = proper_chi_square_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3732a3-0c82-447d-b300-fe1a3c110377",
   "metadata": {},
   "source": [
    "The key insight from this statistical analysis is that while Facebook shows a slightly higher completion rate (25.6%) compared to Email (24.3%), this 1.3 percentage point difference is statistically detectable but practically insignificant. The effect size of Cramer's V = 0.008 falls well below the threshold of 0.1 that researchers consider negligible, confirming that no channel performs meaningfully better or worse than others. This statistical evidence reinforces the earlier finding that all channels share fundamentally similar performance patterns, indicating that The Look's challenges are systemic rather than channel-specific and that marketing resources should be redirected from channel optimization to addressing the underlying purchase funnel inefficiencies that affect all acquisition sources equally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6621ffd9-250d-4c1d-99aa-e927c25fb7db",
   "metadata": {},
   "source": [
    "### Statistical Testing with Chi-Square for if return rates differ across all the Traffic sources\n",
    "I conducted chi-square tests to determine if return rates significantly differ across marketing channels. I performed this test because return percentages alone don't indicate whether differences are meaningful or random, especially with varying sample sizes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9775b9a6-89aa-4ca9-b130-4da8fdaaa7fe",
   "metadata": {},
   "source": [
    "Research Question:\n",
    "Does the traffic source (Search, Organic, Facebook, Email, Display) affect the likelihood of order returning?\n",
    "\n",
    "Hypotheses:\n",
    "Null Hypothesis (H‚ÇÄ):\n",
    "Return rates are equal across all traffic sources.\n",
    "Alternative Hypothesis (H‚ÇÅ):\n",
    "At least one traffic source has a different return rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "99da29e9-a91d-47da-8347-d9e7d1f1483c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing if return rates differ by traffic source...\n",
      "======================================================================\n",
      "STATISTICAL TEST: RETURN RATES BY TRAFFIC SOURCE\n",
      "======================================================================\n",
      "\n",
      "üîç RESEARCH QUESTION:\n",
      "Does traffic source affect order return rate?\n",
      "\n",
      "üìã HYPOTHESES:\n",
      "H‚ÇÄ: Return rates are EQUAL across all traffic sources\n",
      "H‚ÇÅ: At least one traffic source has DIFFERENT return rate\n",
      "\n",
      "üìä TEST DATA (from your analysis):\n",
      "----------------------------------------\n",
      "Source       Returned   Not Returned      Total  Return Rate\n",
      "----------------------------------------\n",
      "Facebook        1,094          9,414     10,508        10.4%\n",
      "Display           727          6,626      7,353         9.9%\n",
      "Search         12,753        114,524    127,277        10.0%\n",
      "Organic         2,757         24,778     27,535        10.0%\n",
      "Email             901          8,185      9,086         9.9%\n",
      "\n",
      "üî¨ TEST: Chi-square test of independence\n",
      "----------------------------------------\n",
      "Chi-square statistic (œá¬≤): 2.0110\n",
      "Degrees of freedom (df): 4\n",
      "p-value: 0.7337352159\n",
      "\n",
      "‚öñÔ∏è DECISION RULE:\n",
      "Significance level: Œ± = 0.05\n",
      "Reject H‚ÇÄ if p-value < 0.05\n",
      "\n",
      "üìà STATISTICAL CONCLUSION:\n",
      "----------------------------------------\n",
      "‚ùå FAIL TO REJECT NULL HYPOTHESIS (p = 0.733735 ‚â• Œ± = 0.05)\n",
      "   Insufficient evidence that\n",
      "   return rates differ by traffic source\n",
      "\n",
      "üìè EFFECT SIZE (Cramer's V):\n",
      "Cramer's V = 0.003326\n",
      "\n",
      "üìã EFFECT SIZE INTERPRETATION:\n",
      "Negligible effect - Return rate differences are trivial\n",
      "\n",
      "üíº BUSINESS IMPLICATION:\n",
      "----------------------------------------\n",
      "No need for channel-specific return prevention strategies\n",
      "Focus on overall return reduction across all channels\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "    def chi_square_test_return_rates():\n",
    "        \"\"\"Test if return rates differ by traffic source\"\"\"\n",
    "        \n",
    "        print(\"=\"*70)\n",
    "        print(\"STATISTICAL TEST: RETURN RATES BY TRAFFIC SOURCE\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # ========== RESEARCH QUESTION ==========\n",
    "        print(\"\\nüîç RESEARCH QUESTION:\")\n",
    "        print(\"Does traffic source affect order return rate?\")\n",
    "        \n",
    "        # ========== HYPOTHESES ==========\n",
    "        print(\"\\nüìã HYPOTHESES:\")\n",
    "        print(\"H‚ÇÄ: Return rates are EQUAL across all traffic sources\")\n",
    "        print(\"H‚ÇÅ: At least one traffic source has DIFFERENT return rate\")\n",
    "        \n",
    "        # ========== DATA ==========\n",
    "        print(\"\\nüìä TEST DATA (from your analysis):\")\n",
    "        print(\"-\"*40)\n",
    "        \n",
    "        # From your table: Traffic Source, Total Items, Returned\n",
    "        sources = ['Facebook', 'Display', 'Search', 'Organic', 'Email']\n",
    "        returned = [1094, 727, 12753, 2757, 901]  # Returned counts\n",
    "        total = [10508, 7353, 127277, 27535, 9086]  # Total items\n",
    "        not_returned = [t - r for t, r in zip(total, returned)]  # Not returned\n",
    "        \n",
    "        # Display data\n",
    "        print(f\"{'Source':10} {'Returned':>10} {'Not Returned':>14} {'Total':>10} {'Return Rate':>12}\")\n",
    "        print(\"-\"*40)\n",
    "        \n",
    "        for i in range(len(sources)):\n",
    "            return_rate = (returned[i] / total[i]) * 100\n",
    "            print(f\"{sources[i]:10} {returned[i]:10,} {not_returned[i]:14,} {total[i]:10,} {return_rate:11.1f}%\")\n",
    "        \n",
    "        # ========== TEST EXECUTION ==========\n",
    "        print(\"\\nüî¨ TEST: Chi-square test of independence\")\n",
    "        print(\"-\"*40)\n",
    "        \n",
    "        # Create contingency table: Returned vs Not Returned by Source\n",
    "        contingency = np.array([returned, not_returned]).T\n",
    "        \n",
    "        # Run Chi-square test\n",
    "        chi2, p_value, dof, expected = stats.chi2_contingency(contingency)\n",
    "        \n",
    "        print(f\"Chi-square statistic (œá¬≤): {chi2:.4f}\")\n",
    "        print(f\"Degrees of freedom (df): {dof}\")\n",
    "        print(f\"p-value: {p_value:.10f}\")\n",
    "        \n",
    "        # Format p-value for display\n",
    "        if p_value < 0.0001:\n",
    "            p_display = \"p < 0.0001\"\n",
    "        else:\n",
    "            p_display = f\"p = {p_value:.6f}\"\n",
    "        \n",
    "        # ========== DECISION RULE ==========\n",
    "        print(\"\\n‚öñÔ∏è DECISION RULE:\")\n",
    "        alpha = 0.05\n",
    "        print(f\"Significance level: Œ± = {alpha}\")\n",
    "        print(f\"Reject H‚ÇÄ if p-value < {alpha}\")\n",
    "        \n",
    "        # ========== STATISTICAL CONCLUSION ==========\n",
    "        print(\"\\nüìà STATISTICAL CONCLUSION:\")\n",
    "        print(\"-\"*40)\n",
    "        \n",
    "        if p_value < alpha:\n",
    "            print(f\"‚úÖ REJECT NULL HYPOTHESIS ({p_display} < Œ± = {alpha})\")\n",
    "            print(\"   Statistically significant evidence that\")\n",
    "            print(\"   return rates differ by traffic source\")\n",
    "        else:\n",
    "            print(f\"‚ùå FAIL TO REJECT NULL HYPOTHESIS ({p_display} ‚â• Œ± = {alpha})\")\n",
    "            print(\"   Insufficient evidence that\")\n",
    "            print(\"   return rates differ by traffic source\")\n",
    "        \n",
    "        # ========== EFFECT SIZE ==========\n",
    "        print(\"\\nüìè EFFECT SIZE (Cramer's V):\")\n",
    "        n = sum(total)\n",
    "        cramers_v = np.sqrt(chi2 / (n * (min(contingency.shape) - 1)))\n",
    "        print(f\"Cramer's V = {cramers_v:.6f}\")\n",
    "        \n",
    "        # Interpret effect size\n",
    "        print(\"\\nüìã EFFECT SIZE INTERPRETATION:\")\n",
    "        if cramers_v < 0.1:\n",
    "            print(\"Negligible effect - Return rate differences are trivial\")\n",
    "        elif cramers_v < 0.2:\n",
    "            print(\"Small effect - Minor practical difference in returns\")\n",
    "        elif cramers_v < 0.3:\n",
    "            print(\"Medium effect - Moderate practical difference\")\n",
    "        else:\n",
    "            print(\"Large effect - Substantial difference in return rates\")\n",
    "        \n",
    "        # ========== BUSINESS IMPLICATION ==========\n",
    "        print(\"\\nüíº BUSINESS IMPLICATION:\")\n",
    "        print(\"-\"*40)\n",
    "        \n",
    "        if p_value >= alpha:\n",
    "            print(\"No need for channel-specific return prevention strategies\")\n",
    "            print(\"Focus on overall return reduction across all channels\")\n",
    "        elif cramers_v < 0.1:\n",
    "            print(\"Statistically significant but practically negligible\")\n",
    "            print(\"Not worth optimizing returns by channel\")\n",
    "        else:\n",
    "            print(\"Both statistically and practically significant\")\n",
    "            print(\"Consider channel-specific return prevention strategies\")\n",
    "            \n",
    "            # Which source has highest return rate?\n",
    "            return_rates = [(sources[i], (returned[i]/total[i])*100) for i in range(len(sources))]\n",
    "            highest_return = max(return_rates, key=lambda x: x[1])\n",
    "            lowest_return = min(return_rates, key=lambda x: x[1])\n",
    "            \n",
    "            print(f\"\\nHighest return rate: {highest_return[0]} ({highest_return[1]:.1f}%)\")\n",
    "            print(f\"Lowest return rate: {lowest_return[0]} ({lowest_return[1]:.1f}%)\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        \n",
    "        return {\n",
    "            'chi2': chi2,\n",
    "            'p_value': p_value,\n",
    "            'cramers_v': cramers_v,\n",
    "            'return_rates': dict(zip(sources, [(r/t)*100 for r, t in zip(returned, total)])),\n",
    "            'decision': 'reject' if p_value < alpha else 'fail to reject'\n",
    "        }\n",
    "    \n",
    "    # Run the return rate test\n",
    "    print(\"Testing if return rates differ by traffic source...\")\n",
    "    return_test_results = chi_square_test_return_rates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e465e95-c5ae-48b9-a6c4-f49149637144",
   "metadata": {},
   "source": [
    "The results show no significant differences (p = 0.7337), with negligible effect size (Cramer's V = 0.0033), confirming that return behavior is consistent across all channels and the focus should be on universal return reduction rather than channel-specific strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60534ddb-1f7d-47ff-aa6a-d5dcc32344d3",
   "metadata": {},
   "source": [
    "# Customer Segmentation Analysis\n",
    "## High-completion Customer Segmentation\n",
    "I filtered and analyzed individual customer performance rather than aggregate channel statistics to identify high-value customers. I conducted this analysis because aggregate metrics mask individual performance patterns, and businesses need to identify specific customers for targeted retention strategies rather than treating all customers within a channel as homogeneous. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f444b388-bd91-4e5e-9dbc-b12577911e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5228 best customers\n",
      "\n",
      "First 5 best customers:\n",
      "    user_id  total_items  completed  returned  cancelled  completion_rate  return_rate\n",
      "14       17            7          6         0          0        85.714286          0.0\n",
      "39       48            2          2         0          0       100.000000          0.0\n",
      "50       60            7          6         0          0        85.714286          0.0\n",
      "52       62            2          2         0          0       100.000000          0.0\n",
      "78       99            2          2         0          0       100.000000          0.0\n",
      "\n",
      "üíæ Exported 5228 best customers to: best_customers_5228.csv\n",
      "Columns exported: user_id, first_name, last_name, email, traffic_source, \n",
      "total_items, completed, returned, cancelled, completion_rate, return_rate\n",
      "\n",
      "üìä Best Customers by Traffic Source:\n",
      "traffic_source\n",
      "Search      3629\n",
      "Organic      799\n",
      "Facebook     322\n",
      "Email        246\n",
      "Display      232\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "    # Step 1: Connect data at customer level\n",
    "    customer_orders = pd.merge(\n",
    "        thelook.orders[['order_id', 'user_id']],\n",
    "        thelook.order_items[['order_id', 'status']],\n",
    "        on='order_id'\n",
    "    )\n",
    "    \n",
    "    # Step 2: Group by customer and calculate metrics\n",
    "    customer_stats = customer_orders.groupby('user_id').agg(\n",
    "        total_items=('status', 'count'),\n",
    "        completed=('status', lambda x: (x == 'Complete').sum()),\n",
    "        returned=('status', lambda x: (x == 'Returned').sum()),\n",
    "        cancelled=('status', lambda x: (x == 'Cancelled').sum())\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Step 3: Calculate rates\n",
    "    customer_stats['completion_rate'] = (customer_stats['completed'] / customer_stats['total_items']) * 100\n",
    "    customer_stats['return_rate'] = (customer_stats['returned'] / customer_stats['total_items']) * 100\n",
    "    \n",
    "    # Step 4: Filter best customers\n",
    "    best_customers = customer_stats[\n",
    "        (customer_stats['completion_rate'] > 80) &  # High completion\n",
    "        (customer_stats['return_rate'] < 5) &       # Low returns\n",
    "        (customer_stats['total_items'] >= 2)        # Multiple orders\n",
    "    ]\n",
    "    \n",
    "    print(f\"Found {len(best_customers)} best customers\")\n",
    "    print(\"\\nFirst 5 best customers:\")\n",
    "    print(best_customers.head())\n",
    "    \n",
    "    # Step 5: Add customer details from users table\n",
    "    best_customers_with_details = pd.merge(\n",
    "        best_customers,\n",
    "        thelook.users[['id', 'first_name', 'last_name', 'email', 'traffic_source']],\n",
    "        left_on='user_id',\n",
    "        right_on='id',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Step 6: Export to CSV\n",
    "    output_file = \"best_customers_5228.csv\"\n",
    "    best_customers_with_details.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"\\nüíæ Exported {len(best_customers)} best customers to: {output_file}\")\n",
    "    print(f\"Columns exported: user_id, first_name, last_name, email, traffic_source, \")\n",
    "    print(f\"total_items, completed, returned, cancelled, completion_rate, return_rate\")\n",
    "    \n",
    "    # Optional: Show distribution by traffic source\n",
    "    print(\"\\nüìä Best Customers by Traffic Source:\")\n",
    "    print(best_customers_with_details['traffic_source'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92680982-1bbb-4971-85f6-bc631fc9bb4f",
   "metadata": {},
   "source": [
    "The analysis identified 5,228 best customers with completion rates over 80% and return rates below 5%, distributed proportionally across traffic sources, revealing that high-value customers exist in all channels and that customer quality matters more than acquisition source for retention strategy development."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccff58fe-5e2d-427c-bbd5-0395c152fd73",
   "metadata": {},
   "source": [
    "## High-Return Customer Segmentation\n",
    " I filtered and identified customers with problematic return patterns to understand which individuals consistently return purchases. I conducted this analysis because identifying specific customers with high return rates allows for targeted interventions, such as improved sizing guidance or product recommendations, rather than applying blanket solutions to all customers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "094bc5ba-14b7-4739-98c3-f6e475dcf8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding high-return customers (like we found best customers)...\n",
      "üîç FINDING HIGH-RETURN CUSTOMERS\n",
      "============================================================\n",
      "Found 7406 high-return customers\n",
      "\n",
      "First 5 high-return customers:\n",
      "    user_id  total_items  completed  returned  cancelled  return_rate\n",
      "9        11            2          0         1          0    50.000000\n",
      "19       24            2          1         1          0    50.000000\n",
      "33       41            2          0         2          0   100.000000\n",
      "49       59            3          0         1          2    33.333333\n",
      "58       72            3          0         1          0    33.333333\n",
      "\n",
      "üìä HIGH-RETURN CUSTOMERS BY TRAFFIC SOURCE:\n",
      "--------------------------------------------------\n",
      "traffic_source  customer_count  avg_return_rate  avg_total_items\n",
      "       Display             299        57.846610         3.364548\n",
      "         Email             366        59.005364         3.480874\n",
      "      Facebook             441        57.486413         3.503401\n",
      "       Organic            1092        58.774612         3.394689\n",
      "        Search            5208        58.338101         3.361751\n",
      "\n",
      "üíæ EXPORTED: high_return_customers.csv\n",
      "   Contains: 7,406 high-return customers\n",
      "\n",
      "============================================================\n",
      "‚úÖ ANALYSIS COMPLETE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "    def analyze_returned_customers_simple():\n",
    "        \"\"\"Find customers with high return rates\"\"\"\n",
    "        \n",
    "        print(\"üîç FINDING HIGH-RETURN CUSTOMERS\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Step 1: Connect data at customer level (same as before)\n",
    "        customer_orders = pd.merge(\n",
    "            thelook.orders[['order_id', 'user_id']],\n",
    "            thelook.order_items[['order_id', 'status']],\n",
    "            on='order_id'\n",
    "        )\n",
    "        \n",
    "        # Step 2: Group by customer and calculate metrics\n",
    "        customer_stats = customer_orders.groupby('user_id').agg(\n",
    "            total_items=('status', 'count'),\n",
    "            completed=('status', lambda x: (x == 'Complete').sum()),\n",
    "            returned=('status', lambda x: (x == 'Returned').sum()),\n",
    "            cancelled=('status', lambda x: (x == 'Cancelled').sum())\n",
    "        ).reset_index()\n",
    "        \n",
    "        # Step 3: Calculate return rate\n",
    "        customer_stats['return_rate'] = (customer_stats['returned'] / customer_stats['total_items']) * 100\n",
    "        \n",
    "        # Step 4: Filter high-return customers (like we filtered best customers)\n",
    "        # Criteria: Return rate > 20% AND at least 2 items (to be meaningful)\n",
    "        high_return_customers = customer_stats[\n",
    "            (customer_stats['return_rate'] > 20) &  # High return rate\n",
    "            (customer_stats['total_items'] >= 2)    # Multiple orders to calculate rate\n",
    "        ]\n",
    "        \n",
    "        print(f\"Found {len(high_return_customers)} high-return customers\")\n",
    "        print(\"\\nFirst 5 high-return customers:\")\n",
    "        print(high_return_customers.head())\n",
    "        \n",
    "        # Step 5: Connect to traffic source\n",
    "        high_return_with_source = pd.merge(\n",
    "            high_return_customers,\n",
    "            thelook.users[['id', 'traffic_source', 'first_name', 'last_name', 'email']],\n",
    "            left_on='user_id',\n",
    "            right_on='id',\n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        # Step 6: Group by traffic source\n",
    "        print(\"\\nüìä HIGH-RETURN CUSTOMERS BY TRAFFIC SOURCE:\")\n",
    "        print(\"-\"*50)\n",
    "        \n",
    "        high_return_by_source = high_return_with_source.groupby('traffic_source').agg(\n",
    "            customer_count=('user_id', 'count'),\n",
    "            avg_return_rate=('return_rate', 'mean'),\n",
    "            avg_total_items=('total_items', 'mean')\n",
    "        ).reset_index()\n",
    "        \n",
    "        print(high_return_by_source.to_string(index=False))\n",
    "        \n",
    "        # Step 7: Export to CSV\n",
    "        output_file = \"high_return_customers.csv\"\n",
    "        export_data = high_return_with_source[['user_id', 'first_name', 'last_name', 'email', \n",
    "                                              'traffic_source', 'total_items', 'returned', \n",
    "                                              'return_rate']]\n",
    "        export_data.to_csv(output_file, index=False)\n",
    "        \n",
    "        print(f\"\\nüíæ EXPORTED: {output_file}\")\n",
    "        print(f\"   Contains: {len(high_return_customers):,} high-return customers\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"‚úÖ ANALYSIS COMPLETE\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        return {\n",
    "            'high_return_customers': high_return_customers,\n",
    "            'high_return_by_source': high_return_by_source,\n",
    "            'export_data': export_data\n",
    "        }\n",
    "    \n",
    "    # Run the analysis\n",
    "    print(\"Finding high-return customers (like we found best customers)...\")\n",
    "    returned_analysis = analyze_returned_customers_simple()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81370562-b184-4907-a260-d31e0d71632f",
   "metadata": {},
   "source": [
    "The analysis identified 7,406 high-return customers with return rates exceeding 20%, distributed across all traffic sources with similar average return rates (57-59%), revealing that return behavior is consistent regardless of acquisition channel and requires personalized solutions rather than channel-based approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d04302b-0821-4fd2-be09-9cc4425bb9b7",
   "metadata": {},
   "source": [
    "# High-Cancellation Customer Segmentation\n",
    "I filtered and identified customers who frequently cancel orders before fulfillment to understand pre-purchase abandonment patterns. I conducted this analysis because cancellation behavior indicates potential issues with checkout friction, pricing transparency, or fulfillment expectations that differ from the problematic patterns shown by returns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7f72b104-41b9-4e11-87bc-5e155a423e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding high-cancellation customers...\n",
      "üîç FINDING HIGH-CANCELLATION CUSTOMERS\n",
      "============================================================\n",
      "Found 9623 high-cancellation customers\n",
      "\n",
      "First 5 high-cancellation customers:\n",
      "    user_id  total_items  completed  returned  cancelled  cancellation_rate\n",
      "4         5            3          0         0          3              100.0\n",
      "7         8            2          0         0          2              100.0\n",
      "8         9            6          0         0          6              100.0\n",
      "32       40            2          0         0          1               50.0\n",
      "36       44            2          1         0          1               50.0\n",
      "\n",
      "üìä HIGH-CANCELLATION CUSTOMERS BY TRAFFIC SOURCE:\n",
      "--------------------------------------------------\n",
      "traffic_source  customer_count  avg_cancellation_rate  avg_total_items\n",
      "       Display             352              64.475334         3.159091\n",
      "         Email             464              64.693401         3.116379\n",
      "      Facebook             537              64.326579         3.206704\n",
      "       Organic            1483              64.505410         3.221173\n",
      "        Search            6787              64.973864         3.210108\n",
      "\n",
      "üíæ EXPORTED: high_cancellation_customers.csv\n",
      "   Contains: 9,623 high-cancellation customers\n",
      "\n",
      "üìä COMPARISON: BEST vs HIGH-CANCELLATION CUSTOMERS\n",
      "--------------------------------------------------\n",
      "Best customers:       5,245\n",
      "High-cancellation:    9,623\n",
      "High-return:          [Run previous analysis for this count]\n",
      "\n",
      "============================================================\n",
      "‚úÖ ANALYSIS COMPLETE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "    def analyze_cancelled_customers_simple():\n",
    "        \"\"\"Find customers with high cancellation rates\"\"\"\n",
    "        \n",
    "        print(\"üîç FINDING HIGH-CANCELLATION CUSTOMERS\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Step 1: Connect data at customer level (same as before)\n",
    "        customer_orders = pd.merge(\n",
    "            thelook.orders[['order_id', 'user_id']],\n",
    "            thelook.order_items[['order_id', 'status']],\n",
    "            on='order_id'\n",
    "        )\n",
    "        \n",
    "        # Step 2: Group by customer and calculate metrics\n",
    "        customer_stats = customer_orders.groupby('user_id').agg(\n",
    "            total_items=('status', 'count'),\n",
    "            completed=('status', lambda x: (x == 'Complete').sum()),\n",
    "            returned=('status', lambda x: (x == 'Returned').sum()),\n",
    "            cancelled=('status', lambda x: (x == 'Cancelled').sum())\n",
    "        ).reset_index()\n",
    "        \n",
    "        # Step 3: Calculate cancellation rate\n",
    "        customer_stats['cancellation_rate'] = (customer_stats['cancelled'] / customer_stats['total_items']) * 100\n",
    "        \n",
    "        # Step 4: Filter high-cancellation customers\n",
    "        # Criteria: Cancellation rate > 30% AND at least 2 items\n",
    "        high_cancel_customers = customer_stats[\n",
    "            (customer_stats['cancellation_rate'] > 30) &  # High cancellation rate\n",
    "            (customer_stats['total_items'] >= 2)          # Multiple orders to calculate rate\n",
    "        ]\n",
    "        \n",
    "        print(f\"Found {len(high_cancel_customers)} high-cancellation customers\")\n",
    "        print(\"\\nFirst 5 high-cancellation customers:\")\n",
    "        print(high_cancel_customers.head())\n",
    "        \n",
    "        # Step 5: Connect to traffic source\n",
    "        high_cancel_with_source = pd.merge(\n",
    "            high_cancel_customers,\n",
    "            thelook.users[['id', 'traffic_source', 'first_name', 'last_name', 'email']],\n",
    "            left_on='user_id',\n",
    "            right_on='id',\n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        # Step 6: Group by traffic source\n",
    "        print(\"\\nüìä HIGH-CANCELLATION CUSTOMERS BY TRAFFIC SOURCE:\")\n",
    "        print(\"-\"*50)\n",
    "        \n",
    "        high_cancel_by_source = high_cancel_with_source.groupby('traffic_source').agg(\n",
    "            customer_count=('user_id', 'count'),\n",
    "            avg_cancellation_rate=('cancellation_rate', 'mean'),\n",
    "            avg_total_items=('total_items', 'mean')\n",
    "        ).reset_index()\n",
    "        \n",
    "        print(high_cancel_by_source.to_string(index=False))\n",
    "        \n",
    "        # Step 7: Export to CSV\n",
    "        output_file = \"high_cancellation_customers.csv\"\n",
    "        export_data = high_cancel_with_source[['user_id', 'first_name', 'last_name', 'email', \n",
    "                                              'traffic_source', 'total_items', 'cancelled', \n",
    "                                              'cancellation_rate']]\n",
    "        export_data.to_csv(output_file, index=False)\n",
    "        \n",
    "        print(f\"\\nüíæ EXPORTED: {output_file}\")\n",
    "        print(f\"   Contains: {len(high_cancel_customers):,} high-cancellation customers\")\n",
    "        \n",
    "        # Step 8: Compare with best customers (5,228)\n",
    "        print(\"\\nüìä COMPARISON: BEST vs HIGH-CANCELLATION CUSTOMERS\")\n",
    "        print(\"-\"*50)\n",
    "        \n",
    "        # Recalculate best customers for comparison\n",
    "        customer_stats['completion_rate'] = (customer_stats['completed'] / customer_stats['total_items']) * 100\n",
    "        best_customers = customer_stats[\n",
    "            (customer_stats['completion_rate'] > 80) &\n",
    "            (customer_stats['total_items'] >= 2)\n",
    "        ]\n",
    "        \n",
    "        print(f\"Best customers:       {len(best_customers):,}\")\n",
    "        print(f\"High-cancellation:    {len(high_cancel_customers):,}\")\n",
    "        print(f\"High-return:          [Run previous analysis for this count]\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"‚úÖ ANALYSIS COMPLETE\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        return {\n",
    "            'high_cancel_customers': high_cancel_customers,\n",
    "            'high_cancel_by_source': high_cancel_by_source,\n",
    "            'export_data': export_data\n",
    "        }\n",
    "    \n",
    "    # Run the analysis\n",
    "    print(\"Finding high-cancellation customers...\")\n",
    "    cancel_analysis = analyze_cancelled_customers_simple()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dae3bf-abc6-4730-b02e-4b0592d691c6",
   "metadata": {},
   "source": [
    "The analysis identified 9,623 high-cancellation customers with cancellation rates exceeding 30%, revealing that cancellation issues affect nearly twice as many customers as return problems and are evenly distributed across all channels, indicating systemic checkout or fulfillment process issues rather than channel-specific problems requiring urgent operational improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc572f54-0471-4f00-825f-5b8855429472",
   "metadata": {},
   "source": [
    "# Customer Segment Export & Preparation for Spatial Analysis\n",
    "Based on my customer segmentation export process, I created and verified three customer segment files containing identified high-value, high-return, and high-cancellation customers for further geographic analysis. I conducted this export because spatial analysis requires clean, segmented customer data with geographic coordinates to identify regional patterns and optimize distribution strategies. The successful export of 5,228 best customers, 7,406 high-return customers, and 9,623 high-cancellation customers to CSV format provides the foundation for geographic analysis that will reveal whether customer behavior patterns correlate with location, distance from distribution centers, or regional characteristics, enabling targeted geographic strategies for each segment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "52327e8b-ae63-445a-9d0f-f63dcb053925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for our exported files:\n",
      "‚úÖ best_customers_5228.csv - FOUND\n",
      "   Location: C:\\Users\\PC\\best_customers_5228.csv\n",
      "‚úÖ high_return_customers.csv - FOUND\n",
      "   Location: C:\\Users\\PC\\high_return_customers.csv\n",
      "‚úÖ high_cancellation_customers.csv - FOUND\n",
      "   Location: C:\\Users\\PC\\high_cancellation_customers.csv\n"
     ]
    }
   ],
   "source": [
    "    # Check if our files were created\n",
    "    files_to_check = [\n",
    "        \"best_customers_5228.csv\",\n",
    "        \"high_return_customers.csv\", \n",
    "        \"high_cancellation_customers.csv\"\n",
    "    ]\n",
    "    \n",
    "    print(\"Checking for our exported files:\")\n",
    "    for file in files_to_check:\n",
    "        if os.path.exists(file):\n",
    "            print(f\"‚úÖ {file} - FOUND\")\n",
    "            print(f\"   Location: {os.path.abspath(file)}\")\n",
    "        else:\n",
    "            print(f\"‚ùå {file} - NOT FOUND\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0eb4041-bbe7-4c73-ab93-509def6bd22f",
   "metadata": {},
   "source": [
    "# Insights Communication Strategy\n",
    "Based on my comprehensive analysis of The Look's e-commerce data, I have successfully answered the core business questions regarding customer acquisition effectiveness and purchase funnel performance. The data tells a compelling story of systemic challenges transcending individual marketing channels, with all acquisition sources showing remarkably similar completion rates (24-26%) and return patterns (9.9-10.4%), indicating that the primary issues reside in the purchase process itself rather than channel-specific optimization.\n",
    "\n",
    "My findings directly relate to the original business questions by revealing that channel optimization should not be the primary focus. Instead, resources should be redirected toward improving the overall purchase funnel, as statistical testing confirmed no meaningful differences between channels (p = 0.022 for completion rates with negligible effect size Cramer's V = 0.008, and p = 0.659 for return rates). The customer segmentation analysis further revealed that high-value customers exist across all channels, with 5,228 best customers distributed proportionally by source, emphasizing that customer quality matters more than acquisition source.\n",
    "\n",
    "# Strategic Next Steps & Further Analysis Roadmap\n",
    "While this analysis provides critical insights into current performance, strategic decision-making requires deeper investigation into spatial, economic, and behavioral dimensions. In Part 2, I will expand the analysis through four key areas: spatial analysis to optimize fulfillment by mapping customer locations against distribution centers and identifying regional patterns; advanced customer segmentation to calculate lifetime value and predict churn by traffic source; economic ROI analysis to integrate marketing costs and model optimal budget allocation; and temporal analysis to uncover seasonal trends and campaign impacts. This comprehensive approach will transform current insights into actionable strategies for geographic expansion, personalized marketing, operational efficiency, and optimized return on investment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14f62f2-ee61-4f81-acf4-30cf7169edb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
